#!/usr/local/bin/python3.10
#
# coding=utf-8
#
import os
import sys
import subprocess

import openai
import whisper

cmd_en = True

def die( msg ):
    print( f'ERROR: {msg}' )
    sys.exit( 1 )

def cmd( c, echo=True, echo_stdout=False, can_die=True ):  
    if echo: print( c )
    if cmd_en:
        info = subprocess.run( c, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT )
        if echo_stdout: print( info.stdout )
        if can_die and info.returncode != 0: die( f'command failed: {c}' )
        return info.stdout
    else:
        return ''

openai.api_key   = os.getenv( 'OPENAI_API_KEY' )
model            = 'gpt-3.5-turbo'
context          = ''
is_multi_line    = False

i = 1
while i < len(sys.argv):
    arg = sys.argv[i]
    i += 1
    if   arg == '-m':
        model = sys.argv[i]
        i += 1
    elif arg == '-c':
        context = sys.argv[i]
        i += 1
    elif arg == '-ia': 
        is_italian_audio = int( sys.argv[i] )
        i += 1
    else:
        die( f'unknown option: {arg}' )

skip_first_prompt = False
messages=[ {'role': 'system', 'content': 'Ask me anything.'} ]
if context == 'translations':
    context = 'Here are some phrases in either English or Italian. For each phrase, please output a pair of lines. The first line always shows the English translation. The second line always shows the Italian translation. Then add a blank line after those two lines. That should be the order regardless of whether the original phrase is in English or Italian. If you\'d like to list a couple English/Italian translations, that\'s fine, just separate them with semicolons; Finally, please do not capitalize words unless they are always capitalized. So to summarize, for each phrase your output should be:\n<English translations separate by semicolons>\n<Italian translations separated by semicolons\n\n' 
    is_multi_line = True

elif context == 'transcription':
    audio_file_path = cmd( f'ls -t $HOME/Library/Application*Support/com.apple.voicememos/Recordings/*.m4a | head -1', False )
    audio_file_path = audio_file_path.rstrip()
    print( f'Transcribing latest Voice Memos file:\n{audio_file_path}' )
    wmodel = whisper.load_model( "base" )
    result = wmodel.transcribe( audio_file_path, fp16=False )
    transcribed_text = result['text'] 
    print( f'\nTranscribed text:\n{transcribed_text}' )
    print( f'\nChatGPT corrected text: (wait for it)' )
    context = f'Correggi: {transcribed_text}'
    skip_first_prompt = True

elif context != '':
     die( f'unknown context: {context}' )

def prompt_read( prefix, is_multi_line ):
    prompt = input( prefix )
    if not is_multi_line: return prompt
    while True:
         extra = input( '' )
         if extra == '': return prompt
         prompt += '\n' + extra

while True:
    if skip_first_prompt:
        prompt = context
        context = ''
        skip_first_prompt = False
    else:
        prompt = prompt_read( '', is_multi_line )
        if context != '':
            prompt = context + '\n' + prompt
            context = ''

    messages.append( {'role': 'user', 'content': prompt} )
    print( '-----------------------------------\n' )

    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        max_tokens=1024,
        n=1,
        temperature=0.5,
        top_p=1,
        frequency_penalty=0.0,
        presence_penalty=0.6,
    )
    resp = response['choices'][0]['message']['content']
    messages.append( {'role': 'assistant', 'content': resp} )
    print( f'{resp}' )
    print( '-----------------------------------\n' )
